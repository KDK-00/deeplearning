{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPP636Pok+FZwnSc/pbNHQr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KDK-00/deeplearning/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGDtk5y2WlKJ",
        "outputId": "be896ad4-acdb-4765-a122-c9ae83d23b70"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (5,668 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fSUkhND7V0Kh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Attention\n",
        "import pytesseract\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_image(image_path):\n",
        "    text = pytesseract.image_to_string(Image.open(image_path))\n",
        "    return text"
      ],
      "metadata": {
        "id": "AlRvUMKk9k7K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리 함수\n",
        "def preprocess_data(source_text, target_text):\n",
        "    # 텍스트 정제 및 토큰화 과정 수행\n",
        "    source_tokens = source_text.lower().split()\n",
        "    if target_text:\n",
        "        target_tokens = target_text.lower().split()\n",
        "    else:\n",
        "        target_tokens = ['<start>', '<end>']\n",
        "\n",
        "    # 인코더-디코더 입력 데이터 생성\n",
        "    encoder_input = ... # 여기서 encoder_input을 생성\n",
        "    decoder_input = ... # 여기서 decoder_input을 생성\n",
        "    decoder_output = ... # 여기서 decoder_output을 생성\n",
        "\n",
        "    # 소스/타깃 언어 어휘 사전 크기 계산\n",
        "    source_vocab = len(set(source_tokens)) + 1\n",
        "    target_vocab = len(set(target_tokens)) + 2\n",
        "\n",
        "    return encoder_input, decoder_input, decoder_output, source_vocab, target_vocab"
      ],
      "metadata": {
        "id": "GU2gIu9zV3MP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 번역 모델 생성 함수\n",
        "def create_translation_model(input_dim, output_dim, embedding_dim, units):\n",
        "    # 인코더 구현\n",
        "    encoder_input = Input(shape=(None,))\n",
        "    encoder_embedding = Embedding(input_dim=input_dim, output_dim=embedding_dim)(encoder_input)\n",
        "    encoder_lstm = LSTM(units, return_state=True)\n",
        "    _, encoder_state_h, encoder_state_c = encoder_lstm(encoder_embedding)\n",
        "    encoder_states = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "    # 디코더 구현\n",
        "    decoder_input = Input(shape=(None,))\n",
        "    decoder_embedding = Embedding(input_dim=output_dim, output_dim=embedding_dim)(decoder_input)\n",
        "    decoder_lstm = LSTM(units, return_sequences=True, return_state=True)\n",
        "    decoder_output, decoder_state_h, decoder_state_c = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "    attention = Attention()\n",
        "    context_vector = attention([decoder_output, encoder_state_h, encoder_state_c])\n",
        "    decoder_concat = tf.concat([decoder_output, context_vector], axis=-1)\n",
        "    decoder_dense = Dense(output_dim, activation='softmax')\n",
        "    decoder_output = decoder_dense(decoder_concat)\n",
        "\n",
        "    # 모델 생성\n",
        "    model = Model([encoder_input, decoder_input], decoder_output)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model, encoder_state_h, encoder_state_c, decoder_state_h, decoder_state_c"
      ],
      "metadata": {
        "id": "HOXcbEzzXCwh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "24pibRGNXhBh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "image_path = '/content/gdrive/My Drive/EN_bill.jpg'\n",
        "!ls '/content/gdrive/My Drive/EN_bill.jpg'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z149Lqp6YaH4",
        "outputId": "3f916965-c826-49c4-853a-0306a39949dc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "'/content/gdrive/My Drive/EN_bill.jpg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 번역 수행 함수\n",
        "def translate(source_text, model, source_vocab, target_vocab, encoder_state_h, encoder_state_c, decoder_state_h, decoder_state_c):\n",
        "    # 입력 텍스트 전처리\n",
        "    encoder_input = preprocess_data(source_text, None)\n",
        "    decoder_input = preprocess_data(source_text, None)\n",
        "\n",
        "    # 번역 수행\n",
        "    decoder_output = model.predict([encoder_input, decoder_input, encoder_state_h, encoder_state_c, decoder_state_h, decoder_state_c])\n",
        "    translated_text = decode_output(decoder_output, target_vocab)\n",
        "\n",
        "    return translated_text"
      ],
      "metadata": {
        "id": "OQa7QxSDfyqn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 메인 함수\n",
        "if __name__ == '__main__':\n",
        "    # 이미지에서 텍스트 추출 및 번역\n",
        "    image_path = '/content/gdrive/My Drive/EN_bill.jpg'\n",
        "    source_text = extract_text_from_image(image_path)\n",
        "    encoder_input, decoder_input, decoder_output, source_vocab, target_vocab = preprocess_data(source_text, None)\n",
        "    model, encoder_state_h, encoder_state_c, decoder_state_h, decoder_state_c = create_translation_model(source_vocab, target_vocab, 256, 512)\n",
        "    #translated_text = translate(source_text, model, source_vocab, target_vocab, encoder_state_h, encoder_state_c, decoder_state_h, decoder_state_c)\n",
        "    print(f\"원본 텍스트: {source_text}\")\n",
        "    print(f\"번역 결과: {translate(source_text, model, source_vocab, target_vocab, encoder_state_h, encoder_state_c, decoder_state_h, decoder_state_c):}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        },
        "id": "e74AiP7WXFDc",
        "outputId": "7644ce8e-6e8b-41d6-89c0-91dd4d8814c3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 텍스트:  \n",
            "\n",
            " \n",
            "\n",
            "Tb! 3/1 Chk 1991\n",
            "Jun21'19 07:18PM\n",
            "\n",
            "1 Chand Brut187 10.00\n",
            "1G Kd Vint Chard 15.00\n",
            "1 Cobb Salad 14.00\n",
            "1 FLATBREAD 13.00\n",
            "1 MED SHRIMP PASTA 20.50\n",
            "SUBTOTAL 72.50\n",
            "Tax 5,98\n",
            "TOTAL 78.48\n",
            "GRATULT Ss —\n",
            "\n",
            "TOTAL: ——\n",
            "ROOM: “2a\n",
            "\n",
            "PRINT NANE:\n",
            "\n",
            " \n",
            "\n",
            "CTONATIIRE:\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\f\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'tuple\\'> containing values of types {\"<class \\'int\\'>\", \"<class \\'ellipsis\\'>\"})', \"<class 'keras.src.engine.keras_tensor.KerasTensor'>\"}), <class 'NoneType'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-e958c295266c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#translated_text = translate(source_text, model, source_vocab, target_vocab, encoder_state_h, encoder_state_c, decoder_state_h, decoder_state_c)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"원본 텍스트: {source_text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"번역 결과: {translate(source_text, model, source_vocab, target_vocab, encoder_state_h, encoder_state_c, decoder_state_h, decoder_state_c):}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-17de5897537a>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(source_text, model, source_vocab, target_vocab, encoder_state_h, encoder_state_c, decoder_state_h, decoder_state_c)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# 번역 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_state_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_state_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_state_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_state_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtranslated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1106\u001b[0m             \"Failed to find data adapter that can handle input: {}, {}\".format(\n\u001b[1;32m   1107\u001b[0m                 \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'tuple\\'> containing values of types {\"<class \\'int\\'>\", \"<class \\'ellipsis\\'>\"})', \"<class 'keras.src.engine.keras_tensor.KerasTensor'>\"}), <class 'NoneType'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translated_text = translate(source_text, model, source_vocab, target_vocab, encoder_state_h, encoder_state_c, decoder_state_h, decoder_state_c)\n",
        "translate(source_text, model, source_vocab, target_vocab, encoder_state_h, encoder_state_c, decoder_state_h, decoder_state_c):"
      ],
      "metadata": {
        "id": "fnX_jXWC_tvV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}